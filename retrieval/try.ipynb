{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99ddb377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query: When was Alice's Birthday?\n",
      "Expanded Query: Could you please provide more context such as the full name of Alice, the specific year for which you're inquiring about her birthday, and any additional details that might help narrow down the search results? For instance, is Alice a public figure, a friend, or a family member? Knowing this information will help ensure the most accurate and relevant search results.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# from huggingface_hub import login\n",
    "# login(token=\"your_hf_token_here\")\n",
    "\n",
    "# Initialize the LLM client (using your provided Hugging Face router)\n",
    "client = InferenceClient(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    token=\"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\"\n",
    ")\n",
    "\n",
    "# Initialize the embedding model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "def generate_expanded_query(raw_query: str) -> str:\n",
    "    \"\"\"Uses an LLM to generate a more detailed, specific query.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant designed to rephrase and expand user queries to improve search results.\n",
    "    Rewrite the following user query to be more specific, detailed, and context-rich. Do not answer the question, just rewrite the query.\n",
    "\n",
    "    User Query: {raw_query}\n",
    "    Rewritten Query:\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        # model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        max_tokens=256\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "# Example usage\n",
    "user_query = \"When was Alice's Birthday?\"\n",
    "expanded_query = generate_expanded_query(user_query)\n",
    "\n",
    "print(f\"Original Query: {user_query}\")\n",
    "print(f\"Expanded Query: {expanded_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9f30647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expanded query vector has a dimensionality of: 768\n",
      "The original query vector has a dimensionality of: 768\n"
     ]
    }
   ],
   "source": [
    "def embed_query(query: str) -> list:\n",
    "    \"\"\"Converts a user query (or an expanded query) into a vector embedding.\"\"\"\n",
    "    # The SentenceTransformer model returns a numpy array.\n",
    "    query_embedding_np = model.encode(query)\n",
    "    # Convert the numpy array to a standard Python list\n",
    "    return query_embedding_np.tolist()\n",
    "\n",
    "# Embed the expanded query, not the original one\n",
    "query_vector = embed_query(expanded_query)\n",
    "original_vector = embed_query(user_query)\n",
    "\n",
    "print(f\"The expanded query vector has a dimensionality of: {len(query_vector)}\")\n",
    "print(f\"The original query vector has a dimensionality of: {len(original_vector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4543a85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expanded_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
