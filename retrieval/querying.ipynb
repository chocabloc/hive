from openai import OpenAI
from sentence_transformers import SentenceTransformer
import numpy as np
from huggingface_hub import InferenceClient

# from huggingface_hub import login
# login(token="your_hf_token_here")

# Initialize the LLM client (using your provided Hugging Face router)
client = InferenceClient(
    model="mistralai/Mistral-7B-Instruct-v0.2",
    token="***"
)

# Initialize the embedding model
model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")

def generate_expanded_query(raw_query: str) -> str:
    """Uses an LLM to generate a more detailed, specific query."""
    prompt = f"""
    You are an AI assistant designed to rephrase and expand user queries to improve search results.
    Rewrite the following user query to be more specific, detailed, and context-rich. Do not answer the question, just rewrite the query.

    User Query: {raw_query}
    Rewritten Query:
    """
    completion = client.chat.completions.create(
        # model="mistralai/Mistral-7B-Instruct-v0.2",
        messages=[
            {"role": "user", "content": prompt}
        ],
        temperature=0.1,
        max_tokens=256
    )
    return completion.choices[0].message.content.strip()

# Example usage
user_query = "When was Alice's Birthday?"
expanded_query = generate_expanded_query(user_query)

print(f"Original Query: {user_query}")
print(f"Expanded Query: {expanded_query}")
