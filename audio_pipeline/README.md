## Notebooks in `audio_pipeline/`
- [speaker_recognition.ipynb](audio_pipeline/speaker_recognition.ipynb) — <This is the **most important** script. A working version of what the audio_pipeline tries to achieve - take in the audio recording of a conversation and output diarized transcript with speaker mappings. However, I am yet to tune the UNKNOWN_THRESHOLD hyperparameter (see the code). Apparently, the SpeechBrain model used here can simplify the workflow further and we might not even be required to write the parts of the script responsible for speaker mapping. See [SpeechBrain_EncoderClassifier](https://huggingface.co/speechbrain/spkrec-ecapa-voxceleb#:~:text=This%20repository%20provides%20all%20the%20necessary%20tools%20to,is%20trained%20on%20Voxceleb%201%2B%20Voxceleb2%20training%20data.).>
- [assemblyAI.ipynb](audio_pipeline/assemblyAI.ipynb) — <Example script for doing [AssemblyAI](https://www.assemblyai.com/) API calls. >
- [nemo.ipynb](audio_pipeline/nemo.ipynb) — <Tried writing a script for diarizing using Nvidia's Nemo model. This was before I came across AssemblyAI. As of now, not relevant.>
- [pyannotepynb.ipynb](audio_pipeline/pyannotepynb.ipynb) — <A diarizer using the pyannote library. Complaint - diarizes very slowly and not accurate. Again, not relevant - was written before I came across AssemblyAI.>
